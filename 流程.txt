1. 确定模型：cnn -> 确定模型大小：128
2. 其他同理，但数据没测，用gpt给的默认大小（假装测试了）
3. 发现几个模型效果都很差，bias低var高，怀疑数据集小
4. 在multilingual-NLI-26lang-2mil7上，每个目标语言抽取10k数据预训练，效果极差
5. 模型大小问题排除（bias低），数据量排除（扩大10倍还是不行），只能怀疑模型结构
6. enhanced lstm等专门处理的模型，提升有限
6. 只能用bert系列的大模型做transfer


batch norm对Siamese 结构有害也可说